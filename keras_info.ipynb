{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras_info.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"pYIIf30TDsJk","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["!pip install -q keras"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MY_NT5cFD1nJ","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from __future__ import print_function, division\n","#from tensorflow.python.client import device_lib\n","\n","#print(device_lib.list_local_devices())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"a7OC9CQeofnk","colab_type":"text"},"cell_type":"markdown","source":["# Colaboratory 에서 keras gpu가 weight는 아직 cpu로 해야되는 것 같다.\n","## [keras gpu 어떻게 설정하는지 나와 있는 URL](http://corazzon.github.io/keras-gpu)\n","\n","## Colraboratory 에서 사용하는 gpu  Tesla K80  아직 멀티 gpu (x)\n","\n","## 현재 메모리 13기가와 CPU는 Intel(R) Xeon(R) CPU @ 2.30GHz을 사용할 수 있다."]},{"metadata":{"id":"vU8QWvhrD5_n","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["\n","\n","from keras.datasets import mnist\n","from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, concatenate\n","from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D, Lambda\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.convolutional import UpSampling2D, Conv2D\n","from keras.models import Sequential, Model\n","from keras.optimizers import Adam\n","from keras.utils import to_categorical\n","import keras.backend as K\n","\n","import matplotlib.pyplot as plt\n","\n","import numpy as np\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yAvrvchWAliy","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["class INFOGAN():\n","    def __init__(self):\n","        self.img_rows = 28\n","        self.img_cols = 28\n","        self.channels = 1\n","        self.num_classes = 10\n","        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n","        self.latent_dim = 72\n","\n","\n","        optimizer = Adam(0.0002, 0.5)\n","        losses = ['binary_crossentropy', self.mutual_info_loss]\n","\n","        # Build and compile the generator\n","        self.generator = self.build_generator()\n","        self.generator.compile(loss=['binary_crossentropy'],\n","            optimizer=optimizer)\n","\n","        # Build and the discriminator and recognition network\n","        self.discriminator, self.auxilliary = self.build_disk_and_q_net()\n","\n","        self.discriminator.compile(loss=['binary_crossentropy'],\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # Build and compile the recognition network Q\n","        self.auxilliary.compile(loss=[self.mutual_info_loss],\n","            optimizer=optimizer,\n","            metrics=['accuracy'])\n","\n","        # The generator takes noise and the target label as input\n","        # and generates the corresponding digit of that label\n","        gen_input = Input(shape=(self.latent_dim,))\n","        img = self.generator(gen_input)\n","\n","        # For the combined model we will only train the generator\n","        self.discriminator.trainable = False\n","\n","        # The discriminator takes generated image as input and determines validity\n","        valid = self.discriminator(img)\n","        # The recognition network produces the label\n","        target_label = self.auxilliary(img)\n","\n","        # The combined model  (stacked generator and discriminator)\n","        self.combined = Model(gen_input, [valid, target_label])\n","        self.combined.compile(loss=losses,\n","            optimizer=optimizer)\n","\n","\n","    def build_generator(self):\n","\n","        model = Sequential()\n","\n","        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n","        model.add(Reshape((7, 7, 128)))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(UpSampling2D())\n","        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(UpSampling2D())\n","        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n","        model.add(Activation(\"relu\"))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Conv2D(self.channels, kernel_size=3, padding='same'))\n","        model.add(Activation(\"tanh\"))\n","\n","        gen_input = Input(shape=(self.latent_dim,))\n","        img = model(gen_input)\n","\n","        model.summary()\n","\n","        return Model(gen_input, img)\n","\n","\n","    def build_disk_and_q_net(self):\n","\n","        img = Input(shape=self.img_shape)\n","\n","        # Shared layers between discriminator and recognition network\n","        model = Sequential()\n","        model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Conv2D(512, kernel_size=3, strides=2, padding=\"same\"))\n","        model.add(LeakyReLU(alpha=0.2))\n","        model.add(Dropout(0.25))\n","        model.add(BatchNormalization(momentum=0.8))\n","        model.add(Flatten())\n","\n","        img_embedding = model(img)\n","\n","        # Discriminator\n","        validity = Dense(1, activation='sigmoid')(img_embedding)\n","\n","        # Recognition\n","        q_net = Dense(128, activation='relu')(img_embedding)\n","        label = Dense(self.num_classes, activation='softmax')(q_net)\n","\n","        # Return discriminator and recognition network\n","        return Model(img, validity), Model(img, label)\n","\n","\n","    def mutual_info_loss(self, c, c_given_x):\n","        \"\"\"The mutual information metric we aim to minimize\"\"\"\n","        eps = 1e-8\n","        conditional_entropy = K.mean(- K.sum(K.log(c_given_x + eps) * c, axis=1))\n","        entropy = K.mean(- K.sum(K.log(c + eps) * c, axis=1))\n","\n","        return conditional_entropy + entropy\n","\n","    def sample_generator_input(self, batch_size):\n","        # Generator inputs\n","        sampled_noise = np.random.normal(0, 1, (batch_size, 62))\n","        sampled_labels = np.random.randint(0, self.num_classes, batch_size).reshape(-1, 1)\n","        sampled_labels = to_categorical(sampled_labels, num_classes=self.num_classes)\n","\n","        return sampled_noise, sampled_labels\n","\n","    def train(self, epochs, batch_size=128, save_interval=50):\n","\n","        # Load the dataset\n","        (X_train, y_train), (_, _) = mnist.load_data()\n","\n","        # Rescale -1 to 1\n","        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n","        X_train = np.expand_dims(X_train, axis=3)\n","        y_train = y_train.reshape(-1, 1)\n","\n","        half_batch = int(batch_size / 2)\n","\n","        for epoch in range(epochs):\n","\n","            # ---------------------\n","            #  Train Discriminator\n","            # ---------------------\n","\n","            # Select a random half batch of images\n","            idx = np.random.randint(0, X_train.shape[0], half_batch)\n","            imgs = X_train[idx]\n","\n","            # Sample noise and categorical labels\n","            sampled_noise, sampled_labels = self.sample_generator_input(half_batch)\n","            gen_input = np.concatenate((sampled_noise, sampled_labels), axis=1)\n","            # Generate a half batch of new images\n","            gen_imgs = self.generator.predict(gen_input)\n","\n","            valid = np.ones((half_batch, 1))\n","            fake = np.zeros((half_batch, 1))\n","\n","            # Train on real and generated data\n","            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n","            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n","\n","            # Avg. loss\n","            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n","\n","            # ---------------------\n","            #  Train Generator and Q-network\n","            # ---------------------\n","\n","            # Generator wants to fool the discriminator into believing that the generated\n","            # samples are real\n","            valid = np.ones((batch_size, 1))\n","            # Sample noise and categorical labels\n","            sampled_noise, sampled_labels = self.sample_generator_input(batch_size)\n","            gen_input = np.concatenate((sampled_noise, sampled_labels), axis=1)\n","\n","            # Train the generator\n","            g_loss = self.combined.train_on_batch(gen_input, [valid, sampled_labels])\n","\n","            # Plot the progress\n","            if epoch % 100 == 0 :\n","              print (\"%d [D loss: %.2f, acc.: %.2f%%] [Q loss: %.2f] [G loss: %.2f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss[1], g_loss[2]))\n","\n","            # If at save interval => save generated image samples\n","           # if epoch % save_interval == 0:\n","                #self.save_imgs(epoch)\n","\n","    def save_imgs(self, epoch):\n","        r, c = 10, 10\n","\n","        fig, axs = plt.subplots(r, c)\n","        for i in range(c):\n","            sampled_noise, _ = self.sample_generator_input(c)\n","            label = to_categorical(np.full(fill_value=i, shape=(r,1)), num_classes=self.num_classes)\n","            gen_input = np.concatenate((sampled_noise, label), axis=1)\n","            gen_imgs = self.generator.predict(gen_input)\n","            gen_imgs = 0.5 * gen_imgs + 0.5\n","            for j in range(r):\n","                axs[j,i].imshow(gen_imgs[j,:,:,0], cmap='gray')\n","                axs[j,i].axis('off')\n","        #fig.savefig(\".mnist_%d.png\" % epoch)\n","        #plt.close()\n","\n","    def save_model(self):\n","\n","        def save(model, model_name):\n","            model_path = \"infogan/saved_model/%s.json\" % model_name\n","            weights_path = \"infogan/saved_model/%s_weights.hdf5\" % model_name\n","            options = {\"file_arch\": model_path,\n","                        \"file_weight\": weights_path}\n","            json_string = model.to_json()\n","            open(options['file_arch'], 'w').write(json_string)\n","            model.save_weights(options['file_weight'])\n","\n","        save(self.generator, \"generator\")\n","        save(self.discriminator, \"discriminator\")\n","        save(self.combined, \"adversarial\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"uaTezTIPOX3v","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"output_extras":[{"item_id":1},{"item_id":2},{"item_id":32}],"base_uri":"https://localhost:8080/","height":1207},"outputId":"3deee4bb-8f6d-4944-f98c-15875a6ee95b"},"cell_type":"code","source":["if __name__ == '__main__':\n","    infogan = INFOGAN()\n","    infogan.train(epochs=4000, batch_size=128, save_interval=50)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_5 (Dense)              (None, 6272)              457856    \n","_________________________________________________________________\n","reshape_2 (Reshape)          (None, 7, 7, 128)         0         \n","_________________________________________________________________\n","batch_normalization_7 (Batch (None, 7, 7, 128)         512       \n","_________________________________________________________________\n","up_sampling2d_3 (UpSampling2 (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 14, 14, 128)       147584    \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 14, 14, 128)       0         \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 14, 14, 128)       512       \n","_________________________________________________________________\n","up_sampling2d_4 (UpSampling2 (None, 28, 28, 128)       0         \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 28, 28, 64)        73792     \n","_________________________________________________________________\n","activation_5 (Activation)    (None, 28, 28, 64)        0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 28, 28, 64)        256       \n","_________________________________________________________________\n","conv2d_10 (Conv2D)           (None, 28, 28, 1)         577       \n","_________________________________________________________________\n","activation_6 (Activation)    (None, 28, 28, 1)         0         \n","=================================================================\n","Total params: 681,089\n","Trainable params: 680,449\n","Non-trainable params: 640\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n","  'Discrepancy between trainable weights and collected trainable'\n"],"name":"stderr"},{"output_type":"stream","text":["0 [D loss: 1.73, acc.: 32.81%] [Q loss: 0.69] [G loss: 2.91]\n","100 [D loss: 0.60, acc.: 65.62%] [Q loss: 1.51] [G loss: 0.26]\n","200 [D loss: 0.73, acc.: 53.91%] [Q loss: 0.99] [G loss: 0.05]\n","300 [D loss: 0.81, acc.: 57.03%] [Q loss: 0.89] [G loss: 0.05]\n","400 [D loss: 0.78, acc.: 51.56%] [Q loss: 0.90] [G loss: 0.05]\n","500 [D loss: 0.82, acc.: 52.34%] [Q loss: 0.80] [G loss: 0.02]\n","600 [D loss: 0.86, acc.: 51.56%] [Q loss: 0.86] [G loss: 0.03]\n","700 [D loss: 0.79, acc.: 55.47%] [Q loss: 0.76] [G loss: 0.01]\n","800 [D loss: 0.79, acc.: 49.22%] [Q loss: 0.71] [G loss: 0.01]\n","900 [D loss: 0.77, acc.: 50.78%] [Q loss: 0.69] [G loss: 0.03]\n","1000 [D loss: 0.78, acc.: 55.47%] [Q loss: 0.75] [G loss: 0.01]\n","1100 [D loss: 0.80, acc.: 46.88%] [Q loss: 0.69] [G loss: 0.01]\n","1200 [D loss: 0.82, acc.: 44.53%] [Q loss: 0.74] [G loss: 0.01]\n","1300 [D loss: 0.77, acc.: 53.91%] [Q loss: 0.71] [G loss: 0.01]\n","1400 [D loss: 0.76, acc.: 57.81%] [Q loss: 0.69] [G loss: 0.01]\n","1500 [D loss: 0.80, acc.: 50.00%] [Q loss: 0.70] [G loss: 0.01]\n","1600 [D loss: 0.76, acc.: 52.34%] [Q loss: 0.70] [G loss: 0.00]\n","1700 [D loss: 0.81, acc.: 53.91%] [Q loss: 0.70] [G loss: 0.01]\n","1800 [D loss: 0.79, acc.: 52.34%] [Q loss: 0.69] [G loss: 0.02]\n","1900 [D loss: 0.77, acc.: 55.47%] [Q loss: 0.66] [G loss: 0.01]\n","2000 [D loss: 0.79, acc.: 49.22%] [Q loss: 0.75] [G loss: 0.01]\n","2100 [D loss: 0.76, acc.: 49.22%] [Q loss: 0.69] [G loss: 0.01]\n","2200 [D loss: 0.81, acc.: 48.44%] [Q loss: 0.69] [G loss: 0.00]\n","2300 [D loss: 0.79, acc.: 52.34%] [Q loss: 0.71] [G loss: 0.00]\n","2400 [D loss: 0.80, acc.: 47.66%] [Q loss: 0.70] [G loss: 0.00]\n","2500 [D loss: 0.80, acc.: 50.78%] [Q loss: 0.73] [G loss: 0.01]\n","2600 [D loss: 0.76, acc.: 51.56%] [Q loss: 0.70] [G loss: 0.01]\n","2700 [D loss: 0.77, acc.: 52.34%] [Q loss: 0.72] [G loss: 0.00]\n","2800 [D loss: 0.76, acc.: 46.88%] [Q loss: 0.69] [G loss: 0.00]\n","2900 [D loss: 0.76, acc.: 51.56%] [Q loss: 0.67] [G loss: 0.01]\n"],"name":"stdout"}]}]}